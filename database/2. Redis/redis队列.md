# Redis和专业的消息队列如何选？为什么？

原创2021-04-23 13:50·[猿话](https://www.toutiao.com/c/user/token/MS4wLjABAAAAAKYZCukTogvZpFbV3Sexl18x54FoDlsw8RTwZrRhKac/?source=tuwen_detail)

![Redis和专业的消息队列如何选？为什么？](img/6b83b4dc76fe4048a4924709bb3e339b)



面试过的程序员们，应该大都遇到过这样的问题："Redis和专业的消息队列我们该如何选？为什么？"

有些人认为 Redis 很轻量，用作队列很方便。但有些人也认为 Redis 会「丢」数据，最好还是用「专业」的队列中间件更稳妥。

那你觉得究竟哪种方案更好呢？

下面，我就和大家聊一聊把 Redis 当作队列，究竟是否合适这个问题。我会从简单到复杂，一步步带你梳理其中的细节，把这个问题真正地讲清楚。

# List 队列

## 使用

首先，我们先从最简单的场景开始讲起。

如果你的业务需求足够简单，想把 Redis 当作队列来使用，那最先想到的肯定就是使用 List 这个数据类型。因为 List 底层的实现就是一个「链表」，在头部和尾部操作元素，时间复杂度都是 O(1)，这意味着它非常符合消息队列的模型。

如果把 List 当作队列，你可以这么来用。生产者使用 LPUSH 发布消息：

![Redis和专业的消息队列如何选？为什么？](img/60e75c507bbd4a08b4d6a5328c8d0c20)



消费者使用 RPOP 拉取消息：

![Redis和专业的消息队列如何选？为什么？](img/ff9d2fd0744742808fb4732ef63b13fd)



这个模型非常简单，也很容易理解。

![Redis和专业的消息队列如何选？为什么？](img/903e2d0165dc4566bdca106e564846bb)



但有个小问题是，当队列中已经没有消息了，消费者在执行 RPOP 时，会返回 NULL。

![Redis和专业的消息队列如何选？为什么？](img/9b67751337ea4e77b18acb1eea90ae66)

## 死循环-->cpu空转-->等待

而我们在编写消费者逻辑时，一般是一个「死循环」，这个逻辑需要不断地从队列中拉取消息进行处理，伪代码一般会这么写：

![Redis和专业的消息队列如何选？为什么？](img/671de4029b97478d9ff73af5a37e0e06)



如果此时队列为空，那消费者依旧会频繁拉取消息，这会造成「CPU 空转」，不仅浪费 CPU 资源，还会对 Redis 造成压力。

要解决这个问题，也很简单，当队列为空时，我们可以让消费者「休眠」一会后再去尝试拉取消息。

![Redis和专业的消息队列如何选？为什么？](img/0bb0c31722e64fccb5863969744f482a)



CPU 空转问题虽然解决了，但又有另外一个问题：当消费者在休眠等待时，有新消息来了，那消费者处理新消息就会存在「延迟」。

假设设置的休眠时间是 2s，那新消息最多存在 2s 的延迟。

要想缩短这个延迟，只能减小休眠的时间。但休眠时间越小，又有可能引发 CPU 空转问题。这似乎进入了一个死胡同。

## 阻塞 BRPOP / BLPOP

那如何做，既能及时处理新消息，还能避免 CPU 空转呢？Redis 是否存在这样一种机制：如果队列为空，消费者在拉取消息时就「阻塞等待」，一旦有新消息过来，就通知我的消费者立即处理新消息呢？

幸运的是，Redis 确实提供了「阻塞式」拉取消息的命令：BRPOP / BLPOP，这里的 B 指的是阻塞（Block）。

![Redis和专业的消息队列如何选？为什么？](img/f60d7b461d8c48d09225b84c58ed7745)



现在，你可以这样来拉取消息了：

![Redis和专业的消息队列如何选？为什么？](img/5e9caab3b5bf426ca25e1c9ef040b127)



BRPOP 这种阻塞式方式，还支持传入一个「超时时间」，如果设置为 0，则表示不设置超时，直到有新消息才返回，否则会在指定的超时时间后返回 NULL。

这个方案不错，既兼顾了效率，还避免了 CPU 空转问题，一举两得。

> 注意：如果设置的超时时间太长，这个连接太久没有活跃过，可能会被 Redis Server 判定为无效连接，之后 Redis Server 会强制把这个客户端踢下线。所以，采用这种方案，客户端要有重连机制。

## 缺点

解决了消息处理不及时的问题，你可以再思考一下，这种队列模型，有什么缺点？

我们一起来分析一下：

1. **不支持重复消费**：消费者拉取消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费，即不支持多个消费者消费同一批数据
2. **消息丢失**：消费者拉取到消息后，如果发生异常宕机，那这条消息就丢失了

第一个问题是功能上的，使用 List 做消息队列，它仅仅支持最简单的，一组生产者对应一组消费者，不能满足多组生产者和消费者的业务场景。

第二个问题就比较棘手了，因为从 List 中 POP 一条消息出来后，这条消息就会立即从链表中删除了。也就是说，无论消费者是否处理成功，这条消息都没办法再次消费了。

这也意味着，如果消费者在处理消息时异常宕机，那这条消息就相当于丢失了。

针对这 2 个问题怎么解决呢？我们一个个来看。

# 发布/订阅模型：Pub/Sub

## 使用

从名字就能看出来，这个模块是 Redis 专门是针对「发布/订阅」这种队列模型设计的。

它正好可以解决前面提到的第一个问题：重复消费。

即多组生产者、消费者的场景，我们来看它是如何做的。

Redis 提供了 PUBLISH / SUBSCRIBE 命令，来完成发布、订阅的操作。

![Redis和专业的消息队列如何选？为什么？](img/95b832ab2fc44490acebdcfde2326a0e.png)



假设你想开启 2 个消费者，同时消费同一批数据，就可以按照以下方式来实现。

首先，使用 SUBSCRIBE 命令，启动 2 个消费者，并「订阅」同一个队列。

![Redis和专业的消息队列如何选？为什么？](img/a96b25e0725a4a5ba1c94b3973a64143)



此时，2 个消费者都会被阻塞住，等待新消息的到来。

之后，再启动一个生产者，发布一条消息。

![Redis和专业的消息队列如何选？为什么？](img/8602dfc0448a4f21b916963104d0a3c1)



这时，2 个消费者就会解除阻塞，收到生产者发来的新消息。

![Redis和专业的消息队列如何选？为什么？](img/9152e9ba4d714ccfb908e87f90011f4b)



看到了么，使用 Pub/Sub 这种方案，既支持阻塞式拉取消息，还很好地满足了多组消费者，消费同一批数据的业务需求。

除此之外，Pub/Sub 还提供了「匹配订阅」模式，允许消费者根据一定规则，订阅「多个」自己感兴趣的队列。

![Redis和专业的消息队列如何选？为什么？](img/5ba2d2b3321a4ed19284265ee8a395df)



这里的消费者，订阅了 queue.* 相关的队列消息。

之后，生产者分别向 queue.p1 和 queue.p2 发布消息。

![Redis和专业的消息队列如何选？为什么？](img/ec9d5ff5135a4deb83a8a516fa560714)



这时再看消费者，它就可以接收到这 2 个生产者的消息了。

![Redis和专业的消息队列如何选？为什么？](img/909e3cc5ecaf4a288d956df3cbf4d9d7)



![Redis和专业的消息队列如何选？为什么？](img/9ea5a0f5ef224e688408085591490524.png)



我们可以看到，Pub/Sub 最大的优势就是，支持多组生产者、消费者处理消息。

## 缺点

讲完了它的优点，那它有什么缺点呢？

其实，Pub/Sub 最大问题是：**丢数据**。

如果发生以下场景，就有可能导致数据丢失：

1. 消费者下线
2. Redis 宕机
3. 消息堆积

究竟是怎么回事？

这其实与 Pub/Sub 的实现方式有很大关系。

Pub/Sub 在实现时非常简单，它没有基于任何数据类型，也没有做任何的数据存储，它只是单纯地为生产者、消费者建立「数据转发通道」，把符合规则的数据，从一端转发到另一端。

一个完整的发布、订阅消息处理流程是这样的：

1. 消费者订阅指定队列，Redis 就会记录一个映射关系：队列->消费者
2. 生产者向这个队列发布消息，那 Redis 就从映射关系中找出对应的消费者，把消息转发给它

![Redis和专业的消息队列如何选？为什么？](img/ba1ce23ab6ef496488ecc1cdbab5948b)



看到了么，整个过程中，没有任何的数据存储，一切都是实时转发的。

这种设计方案，就导致了上面提到的那些问题。

例如，如果一个消费者异常挂掉了，它再重新上线后，只能接收新的消息，在下线期间生产者发布的消息，因为找不到消费者，都会被丢弃掉。

如果所有消费者都下线了，那生产者发布的消息，因为找不到任何一个消费者，也会全部「丢弃」。

所以，当你在使用 Pub/Sub 时，一定要注意：**消费者必须先订阅队列，生产者才能发布消息，否则消息会丢失。**

这也是前面讲例子时，我们让消费者先订阅队列，之后才让生产者发布消息的原因。

另外，因为 Pub/Sub 没有基于任何数据类型实现，所以它也不具备「数据持久化」的能力。

也就是说，Pub/Sub 的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，Pub/Sub 的数据也会全部丢失。

最后，我们来看 Pub/Sub 在处理「消息积压」时，为什么也会丢数据？

当消费者的速度，跟不上生产者时，就会导致数据积压的情况发生。

如果采用 List 当作队列，消息积压时，会导致这个链表很长，最直接的影响就是，Redis 内存会持续增长，直到消费者把所有数据都从链表中取出。

但 Pub/Sub 的处理方式却不一样，当消息积压时，有可能会导致**消费失败和消息丢失**！

这是怎么回事？

还是回到 Pub/Sub 的实现细节上来说。

每个消费者订阅一个队列时，Redis 都会在 Server 上给这个消费者在分配一个「缓冲区」，这个缓冲区其实就是一块内存。

当生产者发布消息时，Redis 先把消息写到对应消费者的缓冲区中。

之后，消费者不断地从缓冲区读取消息，处理消息。

![Redis和专业的消息队列如何选？为什么？](img/07be78b1c12f4234b7aaeff36943f53d)



但是，问题就出在这个缓冲区上。

因为这个缓冲区其实是有「上限」的（可配置），如果消费者拉取消息很慢，就会造成生产者发布到缓冲区的消息开始积压，缓冲区内存持续增长。

如果超过了缓冲区配置的上限，此时，Redis 就会「强制」把这个消费者踢下线。

这时消费者就会消费失败，也会丢失数据。

如果你有看过 Redis 的配置文件，可以看到这个缓冲区的默认配置：
client-output-buffer-limit pubsub 32mb 8mb 60。

它的参数含义如下：

- 32mb：缓冲区一旦超过 32MB，Redis 直接强制把消费者踢下线
- 8mb + 60：缓冲区超过 8MB，并且持续 60 秒，Redis 也会把消费者踢下线

Pub/Sub 的这一点特点，是与 List 作队列差异比较大的。

从这里你应该可以看出，**List 其实是属于「拉」模型，而 Pub/Sub 其实属于「推」模型**。

List 中的数据可以一直积压在内存中，消费者什么时候来「拉」都可以。

但 Pub/Sub 是把消息先「推」到消费者在 Redis Server 上的缓冲区中，然后等消费者再来取。

当生产、消费速度不匹配时，就会导致缓冲区的内存开始膨胀，Redis 为了控制缓冲区的上限，所以就有了上面讲到的，强制把消费者踢下线的机制。

好了，现在我们总结一下 Pub/Sub 的优缺点：

1. 支持发布 / 订阅，支持多组生产者、消费者处理消息
2. 消费者下线，数据会丢失
3. 不支持数据持久化，Redis 宕机，数据也会丢失
4. 消息堆积，缓冲区溢出，消费者会被强制踢下线，数据也会丢失

有没有发现，除了第一个是优点之外，剩下的都是缺点。

所以，很多人看到 Pub/Sub 的特点后，觉得这个功能很「鸡肋」。

也正是以上原因，Pub/Sub 在实际的应用场景中用得并不多。

> 目前只有哨兵集群和 Redis 实例通信时，采用了 Pub/Sub 的方案，因为哨兵正好符合即时通讯的业务场景。

我们再来看一下，Pub/Sub 有没有解决，消息处理时异常宕机，无法再次消费的问题呢？

其实也不行，Pub/Sub 从缓冲区取走数据之后，数据就从 Redis 缓冲区删除了，消费者发生异常，自然也无法再次重新消费。

好，现在我们重新梳理一下，我们在使用消息队列时的需求。

当我们在使用一个消息队列时，希望它的功能如下：

- 支持阻塞等待拉取消息
- 支持发布 / 订阅模式
- 消费失败，可重新消费，消息不丢失
- 实例宕机，消息不丢失，数据可持久化
- 消息可堆积

Redis 除了 List 和 Pub/Sub 之外，还有符合这些要求的数据类型吗？

其实，Redis 的作者也看到了以上这些问题，也一直在朝着这些方向努力着。

Redis 作者在开发 Redis 期间，还另外开发了一个开源项目 disque。

这个项目的定位，就是一个基于内存的分布式消息队列中间件。

但由于种种原因，这个项目一直不温不火。

终于，在 Redis 5.0 版本，作者把 disque 功能移植到了 Redis 中，并给它定义了一个新的数据类型：**Stream**。

下面我们就来看看，它能符合上面提到的这些要求吗？

# 趋于成熟的队列：Stream

我们来看 Stream 是如何解决上面这些问题的。

我们依旧从简单到复杂，依次来看 Stream 在做消息队列时，是如何处理的？

首先，Stream 通过 XADD 和 XREAD 完成最简单的生产、消费模型：

- XADD：发布消息
- XREAD：读取消息

生产者发布 2 条消息：

![Redis和专业的消息队列如何选？为什么？](img/82dd74dd9f3b4bb9b0a0c9d2885f3c30)



使用 XADD 命令发布消息，其中的「*」表示让 Redis 自动生成唯一的消息 ID。

这个消息 ID 的格式是「时间戳-自增序号」。

消费者拉取消息：

![Redis和专业的消息队列如何选？为什么？](img/f3ab4a90c61246e09010a4578d22a837)




如果想继续拉取消息，需要传入上一条消息的 ID：

![Redis和专业的消息队列如何选？为什么？](img/851d9ce94994454aa32a4762945af3c3)




没有消息，Redis 会返回 NULL。

![Redis和专业的消息队列如何选？为什么？](img/6e5e8793d5134dd598645d0e8779395c)



以上就是 Stream 最简单的生产、消费。

> 这里不再重点介绍 Stream 命令的各种参数，我在例子中演示时，凡是大写的单词都是「固定」参数，凡是小写的单词，都是可以自己定义的，例如队列名、消息长度等等，下面的例子规则也是一样，为了方便你理解，这里有必要提醒一下。

下面我们来看，针对前面提到的消息队列要求，Stream 都是如何解决的？

**1) Stream 是否支持「阻塞式」拉取消息？**

可以的，在读取消息时，只需要增加 BLOCK 参数即可。

![Redis和专业的消息队列如何选？为什么？](img/f767e21a026f4f17a88108c63840c9e1)



这时，消费者就会阻塞等待，直到生产者发布新的消息才会返回。

**2) Stream 是否支持发布 / 订阅模式？**

也没问题，Stream 通过以下命令完成发布订阅：

- XGROUP：创建消费者组
- XREADGROUP：在指定消费组下，开启消费者拉取消息

下面我们来看具体如何做？

首先，生产者依旧发布 2 条消息：

![Redis和专业的消息队列如何选？为什么？](img/06cfb284886240b696ef39b58b17b436)



之后，我们想要开启 2 组消费者处理同一批数据，就需要创建 2 个消费者组：

![Redis和专业的消息队列如何选？为什么？](img/301a6ce70e014132bd3e10056f7f3c2f)



消费者组创建好之后，我们可以给每个「消费者组」下面挂一个「消费者」，让它们分别处理同一批数据。

第一个消费组开始消费：

![Redis和专业的消息队列如何选？为什么？](img/d169e11bcf034d97a79ab5b57ec51439)



同样地，第二个消费组开始消费：

![Redis和专业的消息队列如何选？为什么？](img/a5470a1287634b4ca308c62e27b5b150)



我们可以看到，这 2 组消费者，都可以获取同一批数据进行处理了。

这样一来，就达到了多组消费者「订阅」消费的目的。

![Redis和专业的消息队列如何选？为什么？](img/3e1bae71f23441478d40905cd6dc330e.png)



**3) 消息处理时异常，Stream 能否保证消息不丢失，重新消费？**

除了上面拉取消息时用到了消息 ID，这里为了保证重新消费，也要用到这个消息 ID。

当一组消费者处理完消息后，需要执行 XACK 命令告知 Redis，这时 Redis 就会把这条消息标记为「处理完成」。

![Redis和专业的消息队列如何选？为什么？](img/1948fd365cb04875bb8d3e231cdbaad2)



![Redis和专业的消息队列如何选？为什么？](img/a2982425f809427fa6b24f182fc5ea57.png)



如果消费者异常宕机，肯定不会发送 XACK，那么 Redis 就会依旧保留这条消息。

待这组消费者重新上线后，Redis 就会把之前没有处理成功的数据，重新发给这个消费者。这样一来，即使消费者异常，也不会丢失数据了。

![Redis和专业的消息队列如何选？为什么？](img/d1890d417967464ea6348e586dee2143)



**4) Stream 数据会写入到 RDB 和 AOF 做持久化吗？**

Stream 是新增加的数据类型，它与其它数据类型一样，每个写操作，也都会写入到 RDB 和 AOF 中。

我们只需要配置好持久化策略，这样的话，就算 Redis 宕机重启，Stream 中的数据也可以从 RDB 或 AOF 中恢复回来。

**5) 消息堆积时，Stream 是怎么处理的？**

其实，当消息队列发生消息堆积时，一般只有 2 个解决方案：

1. 生产者限流：避免消费者处理不及时，导致持续积压
2. 丢弃消息：中间件丢弃旧消息，只保留固定长度的新消息

而 Redis 在实现 Stream 时，采用了第 2 个方案。

在发布消息时，你可以指定队列的最大长度，防止队列积压导致内存爆炸。

![Redis和专业的消息队列如何选？为什么？](img/cc65f252a45e475b9a040ad90d01dc44)



当队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。

这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。

> 除了以上介绍到的命令，Stream 还支持查看消息长度（XLEN）、查看消费者状态（XINFO）等命令，使用也比较简单，你可以查询官方文档了解一下，这里就不过多介绍了。

好了，通过以上介绍，我们可以看到，Redis 的 Stream 几乎覆盖到了消息队列的各种场景，是不是觉得很完美？

**既然它的功能这么强大，这是不是意味着，Redis 真的可以作为专业的消息队列中间件来使用呢？**

但是还「差一点」，就算 Redis 能做到以上这些，也只是「趋近于」专业的消息队列。

原因在于 Redis 本身的一些问题，如果把其定位成消息队列，还是有些欠缺的。

到这里，就不得不把 Redis 与专业的队列中间件做对比了。

下面我们就来看一下，Redis 在作队列时，到底还有哪些欠缺？

# 与专业的消息队列对比

其实，一个专业的消息队列，必须要做到两大块：

1. 消息不丢
2. 消息可堆积

前面我们讨论的重点，很大篇幅围绕的是第一点展开的。

这里我们换个角度，从一个消息队列的「使用模型」来分析一下，怎么做，才能保证数据不丢？

使用一个消息队列，其实就分为三大块：**生产者、队列中间件、消费者**。

![Redis和专业的消息队列如何选？为什么？](img/1300efde4cbc45ed9b38270982a4f92c.png)



消息是否会发生丢失，其重点也就在于以下 3 个环节：

1. 生产者会不会丢消息？
2. 消费者会不会丢消息？
3. 队列中间件会不会丢消息？

**1) 生产者会不会丢消息？**

当生产者在发布消息时，可能发生以下异常情况：

1. 消息没发出去：网络故障或其它问题导致发布失败，中间件直接返回失败
2. 不确定是否发布成功：网络问题导致发布超时，可能数据已发送成功，但读取响应结果超时了

如果是情况 1，消息根本没发出去，那么重新发一次就好了。

如果是情况 2，生产者没办法知道消息到底有没有发成功？所以，为了避免消息丢失，它也只能继续重试，直到发布成功为止。

> 生产者一般会设定一个最大重试次数，超过上限依旧失败，需要记录日志报警处理。

也就是说，生产者为了避免消息丢失，只能采用失败重试的方式来处理。

但发现没有？这也意味着消息可能会重复发送。

是的，在使用消息队列时，要保证消息不丢，宁可重发，也不能丢弃。

那消费者这边，就需要多做一些逻辑了。

对于敏感业务，当消费者收到重复数据数据时，要设计幂等逻辑，保证业务的正确性。

从这个角度来看，生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。

所以，无论是 Redis 还是专业的队列中间件，生产者在这一点上都是可以保证消息不丢的。

**2) 消费者会不会丢消息？**

这种情况就是我们前面提到的，消费者拿到消息后，还没处理完成，就异常宕机了，那消费者还能否重新消费失败的消息？

要解决这个问题，消费者在处理完消息后，必须「告知」队列中间件，队列中间件才会把标记已处理，否则仍旧把这些数据发给消费者。

这种方案需要消费者和中间件互相配合，才能保证消费者这一侧的消息不丢。

无论是 Redis 的 Stream，还是专业的队列中间件，例如 RabbitMQ、Kafka，其实都是这么做的。

所以，从这个角度来看，Redis 也是合格的。

**3) 队列中间件会不会丢消息？**

前面 2 个问题都比较好处理，只要客户端和服务端配合好，就能保证生产端、消费端都不丢消息。

但是，如果队列中间件本身就不可靠呢？

毕竟生产者和消费者都依赖它，如果它不可靠，那么生产者和消费者无论怎么做，都无法保证数据不丢。

在这个方面，Redis 其实没有达到要求。

Redis 在以下 2 个场景下，都会导致数据丢失。

1. AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能
2. 主从复制也是异步的，主从切换时，也存在丢失数据的可能（从库还未同步完成主库发来的数据，就被提成主库）

基于以上原因我们可以看到，**Redis 本身的无法保证严格的数据完整性**。

所以，如果把 Redis 当做消息队列，在这方面是有可能导致数据丢失的。

再来看那些专业的消息队列中间件是如何解决这个问题的？

像 RabbitMQ 或 Kafka 这类专业的队列中间件，在使用时，一般是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，以此保证消息的完整性。这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。

也正因为如此，RabbitMQ、Kafka在设计时也更复杂。毕竟，它们是专门针对队列场景设计的。

但 Redis 的定位则不同，它的定位更多是当作缓存来用，它们两者在这个方面肯定是存在差异的。

最后，我们来看消息积压怎么办？

**4) 消息积压怎么办？**

因为 Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。

所以，Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。

但 Kafka、RabbitMQ 这类消息队列就不一样了，它们的数据都会存储在磁盘上，磁盘的成本要比内存小得多，当消息积压时，无非就是多占用一些磁盘空间，相比于内存，在面对积压时也会更加「坦然」。

综上，我们可以看到，把 Redis 当作队列来使用时，始终面临的 2 个问题：

1. Redis 本身可能会丢数据
2. 面对消息积压，Redis 内存资源紧张

到这里，Redis 是否可以用作队列，我想这个答案你应该会比较清晰了。

如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。

而且，Redis 相比于 Kafka、RabbitMQ，部署和运维也更加轻量。

如果你的业务场景对于数据丢失非常敏感，而且写入量非常大，消息积压时会占用很多的机器资源，那么我建议你使用专业的消息队列中间件。

# redis 客户端断开连接_Redis延时队列，这次彻底给你整明白了

https://blog.csdn.net/weixin_31304817/article/details/112176486?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-9&spm=1001.2101.3001.4242

