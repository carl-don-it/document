# 事务TCL

## 介绍

事务执行是一个整体， 所有的 SQL 语句都必须执行成功。如果其中有 1 条 SQL 语句出现异常， 则所有的SQL 语句都要回滚，整个业务执行失败。  保证原子操作。（多线程中不保证线程切换问题）

> 注意：
>
> ​	事务是原子操作，但并不保证（事务级别：业务）并发问题，锁机制保证（数据级别：行、表）并发问题

## 四大特性 ACID

| 事务特性               | 含义                                                         |
| ---------------------- | ------------------------------------------------------------ |
| 原子性（ Atomicity）   | 每个事务都是一个整体，不可再拆分，事务中所有的 SQL 语句要么都执行成功， 要么都失败。 |
| 一致性（ Consistency） | 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设[约束](https://zh.wikipedia.org/wiki/数据完整性)、[触发器](https://zh.wikipedia.org/wiki/触发器_(数据库))、[级联回滚](https://zh.wikipedia.org/wiki/级联回滚)等。可以简单的把一致性理解为正确性或者完整性。 |
| 隔离性（ Isolation）   | 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。 |
| 持久性（ Durability）  | 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 |

## 事务操作

```mysql
-- 1. 开启事务
set autocommit = 0 ; -- 关闭自动commit； MySQL 默认每一条 DML(增删改)语句都是一个单独的事务，每条语句都会自动开启一个事务

SET TRANSACTION, begin  -- 显式开启事务，并且自动触发commit，因此嵌套事务没用
COMMIT  
ROLLBACK  -- 回滚，如果不回滚，下次事务会把这些一起提交

-- 2. 保留点
-- 在事务处理块中合适的位置放置占位符。这样，如果需要回退，可以回退到某个占位符。
-- 保留点在事务处理完成（执行一条ROLLBACK或COMMIT）后自动释放。
SAVEPOINT [identifier] 	-- 设置保存点
ROLLBACK TO [identifier] 	-- 回滚到保留点
RELEASE SAVEPOINT 	  -- 释放

-- 3. 事务失败需要 rollback，然后重新开启事务
```

##   事务原理

事务开启之后, 所有的操作都会临时保存到事务日志中, 事务日志只有在得到 commit 命令才会同步到数据表中，其他任何情况都会清空事务日志(rollback，断开连接)  **必须清空**

<img src="img/1574415867653.png" alt="1574415867653" style="zoom: 96%;" />

## 事务的隔离级别

### 事务并发问题

事务在操作时的**理想状态**： 所有的事务之间保持隔离，互不影响。因为并发操作，多个用户同时访问同一个数据。可能引发并发访问的问题：

| 并发访问的问题 | 含义                                                         |
| -------------- | ------------------------------------------------------------ |
| 脏读           | 一个事务读取到了另一个事务中尚未提交的数据                   |
| 不可重复读     | 一个事务中两次读取的**数据内容**不一致，要求的是一个事务中多次读取时数据是一致的， 这是另一个事务 update 时引发的问题 |
| 幻读           | 一个事务中两次读取的数据的**数量**不一致，要求在一个事务多次读取的数据的数量是一致的，这是insert 或 delete 时引发的问题 |

### 四大隔离级别

#### 介绍

| 级别 | 名字     | 隔离级别         | 脏读 | 不可重复读 | 幻读 | 数据库默认隔离级别   |
| ---- | -------- | ---------------- | ---- | ---------- | ---- | -------------------- |
| 1    | 读未提交 | read uncommitted | 是   | 是         | 是   |                      |
| 2    | 读已提交 | read committed   | 否   | 是         | 是   | Oracle 和 SQL Server |
| 3    | 可重复读 | repeatable read  | 否   | 否         | 是   | MySQL                |
| 4    | 串行化   | serializable     | 否   | 否         | 否   |                      |

>  隔离级别越高，性能越差，安全性越
>
>    可串行化  ：  保证**读取的范围**内没有新的数据插入，比如事务第一次查询得到某个范围的数据，第二次查询也同样得到了相同范围的数据，中间没有新的数据插入到该范围中。  

#### **命令**

| 命令         | 语句                                               |
| ------------ | -------------------------------------------------- |
| 查询隔离级别 | select @@tx_isolation;                             |
| 设置隔离级别 | set global transaction isolation level 级别字符串; |

> ​	设置后先退出客户端才会生效

#### **演示**

1. 脏读很容易

2. 不可重复读： 先设置隔离机制为：读已提交

    <img src="img/1574425579758.png" alt="1574425579758" style="zoom:96%;" />

3. 串行化：无法演示   

   > 结论：使用 serializable 隔离级别，前面的事务没有执行完，后面其他事务的 增删改 执行不了，但可以查询，可以挡住幻读  

# 并发

## 事务和锁的关系

### 介绍

一条sql语句也是事务

有写锁才可以进行写操作，哪个事务先进行（update，insert，delete）操作，先获得该行写锁，commit后才释放。类似于同步锁。

写锁会排除其他事务对同一行的（update，insert，delete）操作，但可以读取，加读锁。

但是通常一个事务读和写是一体，不允许其他线程先写。

### 区别

1. 开启事务只是保证事务操作的的原子性，无法完全保证并发操作的线程安全问题。**原子操作有可能是多步骤**的，即使是单步骤的操作在**cpu层面也可能是多步骤**的。
2. 并发操作中，由于线程切换，不同的原子操作之间是在cpu中不断切换（类似于java多线程切换），会发生**线程安全问题**，因此需要再用锁机制来保证。

## 分布式锁

并不是一种锁，只是一种实现手段，其实就是乐观锁。

我们可以将我们分布式要操作的资源都定义成表，表结构定义t_lock如下：

id:

resource: 资源

status: 状态 0|1

add_time: 添加时间

update_time: 更新时间

version: 如果采用乐观锁，使用版本号，对当前资源的状态进行更新就加1
大致流程就是：

select id, resource, status,version fromt_lock  where status=0 and id=xxxx;

如果查到了说明没有数据，可以进行update

update t_lock set status=1, version=1,update_time=now() where id=xxxx and status=0 and version=0

否则，说明该锁被其他线程持有，还没有释放

 

缺点：

更新之前会多一次查询，增加了数据库的操作

数据库链接资源宝贵，如果并发量太大，数据库的性能有影响

如果单个数据库存在单点问题，所以最好是高可用的。
————————————————
版权声明：本文为CSDN博主「happy19870612」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/zhanglh046/article/details/78630371

## 乐观锁

 总是认为**不会产生并发问题**（自己业务逻辑），每次去取数据的时候总认为不会有其他线程对数据进行修改，因此不会上锁，但是在更新时会判断其他线程在这之前有没有对数据进行修改，一般会使用版本号机制或CAS操作实现。像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。

####  **1. version方式**

​	一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

```mysql
-- 核心SQL代码：
-- version表示执行的次数
-- 还可以加一个状态量0、1，表示是否允许执行，但是如果服务器挂了，会导致永远阻塞
update table set x=x+1, version=#{version}+1 where id=#{id} and version=#{version};  

-- 解决状态量0、1阻塞的方法，使用时间来决定是否允许执行，最新时间
update XcTask t set t.version = #{version}+1 ,t.updateTime = #{updateTime} where t.id = #{id} and t.version = #{version}
```

####  **2. CAS操作方式**

​	即compare and swap 或者 compare and set，是一种有名的**无锁算法**。

​	**无锁编程**，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。

​	CAS算法涉及到三个操作数 ： 需要读写的内存值 V  ，进行比较的值 A  ， 拟写入的新值 B

​	当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个**自旋操作**，即**不断的重试**。

#### 3. 案例

考虑xc_order将来会集群部署，为了避免任务在1分钟内重复执行，这里使用乐观锁，实现思路如下：

每次取任务时判断当前版本及任务id是否匹配，如果匹配则更新当前版本加1，然后执行任务，如果不匹配则取消执行。

1. 在Dao中增加校验当前版本及任务id的匹配方法

   ```java
   public interface XcTaskRepository extends JpaRepository<XcTask, String> {
       //使用乐观锁方式校验任务id和版本号是否匹配，匹配则版本号加1
       @Modifying
       @Query("update XcTask t set t.version = :version+1 where t.id = :id and t.version = :version")
       public int updateTaskVersion(@Param(value = "id") String id, @Param(value = "version") int version);
       ...
   }
   ```

2. 在service中增加方法，使用乐观锁方法校验任务

   ```java
   @Transactional
   public int getTask(String taskId,int version){
       int i = xcTaskRepository.updateTaskVersion(taskId, version);
       return i;
   }
   ```

3. 执行任务类中修改

   ```java
   ...
       //任务id
       String taskId = xcTask.getId();
       //版本号
       Integer version = xcTask.getVersion();
       //调用乐观锁方法校验任务是否可以执行
       if(taskService.getTask(taskId, version)>0){
       	//发送选课消息
           taskService.publish(xcTask, xcTask.getMqExchange(),xcTask.getMqRoutingkey());
           LOGGER.info.("send choose course task id:{}",taskId);
       }
   ...
       
   /*
   注意：
       如果有多个微服务，并不能保证先更新version的微服务先发送选课消息（大概率，并发不高），有可能被其他线程执行，只要其他微服务运行得够快，重新拿到task然后更新再发送任务。
       但如果是这种高并发情况就不该考虑乐观锁，应该使用悲观锁（不同微服务如何使用悲观锁？或者优化业务逻辑），乐观锁就是在并发不高的情况下使用的
   */
   ```

#### 4. 缺陷

[url](https://blog.csdn.net/qq_34337272/article/details/81072874#commentBox)

1. ABA 问题

   如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。

   JDK 1.5 以后的 `AtomicStampedReference` 类就提供了此种能力，其中的 `compareAndSet` 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

2. 循环时间长开销大

   **自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。** 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

3. 只能保证一个共享变量的原子操作

   CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了`AtomicReference`类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作。所以我们可以使用锁或者利用`AtomicReference`类把多个共享变量合并成一个共享变量来操作。
   

## 悲观锁

### 介绍

​		总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加锁（读锁、写锁等），当其他线程想要访问数据时，都需要阻塞挂起。可以依靠数据库实现，如读锁和写锁等，都是在操作之前加锁，在Java中，synchronized，ReentrantLock的思想也是悲观锁。

用场景：数据争用激烈的环境，以及发生并发冲突时**使用锁保护数据的成本**要低于**回滚事务的成本**的环境中。

#### mysql加锁

```mysql
select lock in share mode（共享锁 = s锁 = 读锁？）
select for update （排他锁 = x锁 = 写锁？）

-- 从官网上查找到对应的章节，属于Locking Reads里面的内容，具体链接如下:locking-reads
/*
这两个语句是在事务内起作用的，所涉及的概念是行锁。它们能够保证当前session事务所锁定的行不会被其他session所修改(这里的修改指更新或者删除)。
两个语句不同的是，一个是加了共享锁而另外一个是加了排它锁。

共享锁允许其他事务加共享锁，可以读取，但是，不允许其他事务去做修改，或者加排它锁。
而排它锁显得更加严格，不允许其他事务加共享锁或者排它锁，更加不允许其他事务修改加锁的行,但可以读取。

注意 ： 无论在使用select lock in share mode 或者 select for update，都应该尽快释放锁。

 https://blog.csdn.net/d6619309/article/details/52688250
*/
```

示例：

> ​	1) 读取一行数据
> ​	2) 根据读取到的数据去更新其他数据
>
> 假设在1)和2)之间，有个其他的user session刚好修改了你读取的那行数据，那么你下面的更新就有可能会出错！因为关联的数据产生了变化！

```mysql
use test;
create table tb_test (
  id int primary key,
  col1 varchar(20)
) engine = innodb default character set = 'utf8';

insert into tb_test(id, col1) values(1, 'AAA');
```

#### 共享锁

##### 介绍

使用示例

```mysql
-- session 1:
set autocommit = 0;
select * from tb_test where id = 1 lock in share mode;
```

```mysql
-- open session 2:
update tb_test set col1 = 'BBB' where id = 1;
-- 这个时候可以观察到session2处于blocking状态…. 
```

```mysql
-- 直到 session 1:
commit;
-- 这个时候session2更新成功了。

-- 长时间block，会断开
[SQL]update  city set name="666" where id ="1";
[Err] 1205 - Lock wait timeout exceeded; try restarting transaction
```

**这里也就验证了lock in share mode可以在事务中保证锁定的行不被其他session所更改，只有在上一个事务释放掉锁后才能进行写操作，但是可以进行读操作。**

##### 注意死锁

**使用lock in share mode具有很高的风险**，看下面的案例:

```mysql
-- session 1:
set autocommit = 0;
select * from tb_test where id = 1 lock in share mode;
```

```mysql
-- open session2:
set autocommit = 0;
select * from tb_test where id = 1 lock in share mode;
```


这个时候两个session同时持有id = 1这行数据的共享锁。这个时候我们在session 1里面执行update操作:

```mysql
-- session 1:
update tb_test set col1 = 'AAA' where id = 1;
```


卡住了!!!! ????这个时候session1必须等待session2退出事务或者等待直到锁超时:

锁超时的情况:

```mysql
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
```

如果我们在session 2里面执行:

```mysql
-- session2:
update tb_test set col1 = 'BBB' where id = 1;

ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
```

这个时候mysql检测到会发生死锁，会中断当前事务该语句的执行，重新开启一个新的事务(应该就是相当于session2先退出事务，然后再开启一个事务吧)。

这个时候session1可以更新成功了。

上面的例子可以看出使用lock in share mode比较危险，很可能因为其他session同时加了这种锁，导致当前session无法进行更新，进而阻塞住。

#### 排他锁

select for update加的是排它锁，所以没有上面`lock in share mode`所产生的死锁，因为一个session加了这种锁，其他session除了读取操作，其他操作都会阻塞，如更改操作，或者加锁，共享锁和排它锁都不可以。

**重点**

> 能则为行锁，否则为表锁；未查到数据则无锁。而 使用'<>','like'等操作时，索引会失效，自然进行的是table lock [参考](https://www.cnblogs.com/wangshiwen/p/9837408.html)

**下面演示一下用法:**

```sql
-- session 1:
set autocommit = 0;
select * from tb_test where id = 1 for update;
```

```mysql
-- open session 2:
update tb_test set col1 = 'BBB' where id = 1;
-- 这个时候session 2处于blocking状态
```

我们手动kill掉session 2, 按`Ctrl + C`。然后执行:

```mysql
-- session 2:
set autocommit = 0;
select * from tb_test where id = 1 for update;
```


还是blocking状态，证明其他session的事务不能对已经加了排它锁(for update)的行再加排它锁。kill掉，再来

```mysql
-- session 2:
set autocommit = 0;
select * from tb_test where id = 1 lock in share mode;
```


还是blocking状态，证明其他session的事务不能对已经加了排它锁(for update)的行再加共享锁(lock in share mode)。

当然，如果使用select for update的时候，如果锁定当前行的事务一直不退出，将会导致其他进行这个行更改操作的session一直阻塞。(没有试是否有超时的情况)

#### 总结

1. 共享锁容易导致死锁，因此目的不是为了写数据，而是为了防止写数据，只读。

2. 对某一资源加排他锁，自身可以进行增删改查，其他人无法进行修改。就是为了写。

3. 先读再写，加排他锁，防止读后被其他线程写了。

   ```mysql
   -- 例子 ： 先读作判断，之后再写
   -- 线程1 ：读（排他锁）~ 写
   -- 线程2 ：读（排他锁）~ 写
   -- 这样两个线程都可以保证读写的业务逻辑正确
   ```

   

#### 行锁

行锁，由字面意思理解，就是给某一行加上锁，也就是一条记录加上锁。

比如之前演示的共享锁语句

SELECT * from city where id = "1"  lock in share mode; 

由于对于city表中，id字段为主键，就也相当于索引。执行加锁时，会将id这个索引为1的记录加上锁，那么这个锁就是行锁。如果没有那么就是锁表。

#### 表锁

表锁，和行锁相对应，给这个表加上锁。

## 总结

两种锁各有优缺点，不可认为一种好于另一种。

> **简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）**

1、对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。

2、对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。

> 补充：
>
> ​	Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称他为“重量级锁”。但是，在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入了偏向锁和轻量级锁以及其他各种优化之后变得在某些情况下并不是那么重了。
>
> ​	synchronized的底层实现主要依靠lock-Free队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下性能远高于CAS。



# 高可用

还有很多文章没有看，折叠起来 mysql主从复制

## 主从复制原理

主服务器数据库的每次操作都会记录在其二进制文件mysql-bin.xxx（该文件可以在mysql目录下的data目录中看到）中，从服务器的I/O线程使用专用账号登录到主服务器中读取该二进制文件，并将文件内容写入到自己本地的中继日志 relay-log 文件中，然后从服务器的SQL线程会根据中继日志中的内容执行SQL语句

![img](img/7236980-ec85513460bb5cd6.webp)

## 作用

1、可以作为备份机制，相当于热备份
2、可以用来做读写分离，均衡数据库负载

## 缺陷

复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。

## 操作

### 1. 锁库，同步数据

主从服务器需要有相同的初态

1. 将主服务器要同步的数据库枷锁，避免同步时数据发生改变

   ```php
   mysql>use db;
   mysql>flush tables with read lock;  
   ```

2. 将主服务器数据库中数据导出

   ```mysql
   mysql> mysqldump -uroot -pxxxx db > db.sql;
   --  这个命令是导出数据库中所有表结构和数据，如果要导出函数和存储过程的话使用
   mysql> mysqldump -R -ndt db -uroot -pxxxx > db.sql
   ```

   其他关于mysql导入导出命令的[戳这里](http://www.cnblogs.com/chevin/p/5683281.html)

3. 将初始数据导入从服务器数据库

   ```php
   mysql>create database db;
   mysql>use db;
   mysql>source db.sql;
   ```

### 2. 主服务器（测试3308）设置为master

1. ini文件

	```ini
	#主数据库端ID号
	server_id = 1           
	 #开启二进制日志                  
	log-bin = mysql-bin    
	#需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可                  
	binlog-do-db = db        
	#将从服务器从主服务器收到的更新记入到从服务器自己的二进制日志文件中                 
	log-slave-updates                        
	#控制binlog的写入频率。每执行多少次事务写入一次(这个参数性能消耗很大，但可减小MySQL崩溃造成的损失) 
	sync_binlog = 1                    
	#这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突
	auto_increment_offset = 1           
	#这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突
	auto_increment_increment = 1            
	#二进制日志自动删除的天数，默认值为0,表示“没有自动删除”，启动时和二进制日志循环时可能删除  
	expire_logs_days = 7                    
	#将函数复制到slave  
	log_bin_trust_function_creators = 1       
	```

2. 重启MySQL，创建允许从服务器同步数据的账户

   ```mysql
   # 创建slave账号account，密码123456
   grant replication slave on *.* to 'slave'@'127.0.0.1' identified by '123456';
   # 更新数据库权限
   flush privileges;
   # 查看主服务器状态
   show master status\G;
   ***************** 1. row ****************
               File: mysql-bin.000355 #当前记录的日志
           Position: 120 #日志中记录的位置  
       Binlog_Do_DB: 
   Binlog_Ignore_DB: 
   ```

### 3. 从服务器（测试3307）接上master

1. ini

   ```ini
   server_id = 2
   log-bin = mysql-bin
   log-slave-updates
   sync_binlog = 0
   #log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作
   innodb_flush_log_at_trx_commit = 0        
   #指定slave要复制哪个库
   replicate-do-db = db         
   #MySQL主从复制的时候，当Master和Slave之间的网络中断，但是Master和Slave无法察觉的情况下（比如防火墙或者路由问题）。Slave会等待slave_net_timeout设置的秒数后，才能认为网络出现故障，然后才会重连并且追赶这段时间主库的数据
   slave-net-timeout = 60                    
   log_bin_trust_function_creators = 1
   ```

2. 连接

   如果从服务器关闭后，那么需要重新走这一步
   
   ```mysql
   -- 如果之前有需要先停下来
   STOP SLAVE 
   
   -- 执行同步命令，设置主服务器ip，使用主服务器给的同步账号密码，同步位置，如果位置不对，需要重新设置，对应上面的show master status
   change master to master_host='127.0.0.1',master_port=3308, master_user='slave',master_password='123456',master_log_file='mysql-bin.000355',master_log_pos=120;
   
   -- 开启同步功能
   start slave;
   
   -- 查看从服务器状态
   show slave status;
   
   -- Slave_IO_Running及Slave_SQL_Running进程必须正常运行，即Yes状态，否则说明同步失败
   若失败查看mysql错误日志中具体报错详情来进行问题定位
   mysql>show slave status\G;
   *************************** 1. row ***************************
                  Slave_IO_State: Waiting for master to send event
                     Master_Host: 10.10.20.111
                     Master_User: account
                     Master_Port: 3306
                   Connect_Retry: 60
                 Master_Log_File: mysql-bin.000033
             Read_Master_Log_Pos: 337523
                  Relay_Log_File: db2-relay-bin.000002
                   Relay_Log_Pos: 337686
           Relay_Master_Log_File: mysql-bin.000033
                Slave_IO_Running: Yes
               Slave_SQL_Running: Yes
                 Replicate_Do_DB:
             Replicate_Ignore_DB:
             ...
   ```

### 4. 解锁

解锁主服务器

```mysql
mysql>unlock tables;
```

### 错误

uuid不能相同，也就是copy数据库后需要修改

地址： `\data\auto.cnf`

# 查询优化

重要性依次向下

## 优化业务逻辑

## 索引

### 1. [什么是索引](https://www.linuxidc.com/Linux/2018-06/152757.htm)

-  **MySQL官方对索引的定义**：

  索引(Index)是帮助MySQL高效获取数据的数据结构。我们可以简单理解为：快速查找排好序的一种数据结构。

- **类型**：

  普通索引，唯一索引，全文索引

Mysql索引主要有两种结构：B+Tree索引和Hash索引。我们平常所说的索引，如果没有特别指明，一般都是指B树结构组织的索引(B+Tree索引)。索引如图所示： 



 ![img](img/180607170774891.jpg) 

最外层浅蓝色磁盘块1里有数据17、35（深蓝色）和指针P1、P2、P3（黄色）。P1指针表示小于17的磁盘块，P2是在17-35之间，P3指向大于35的磁盘块。真实数据存在于叶子节点也就是最底下的一层3、5、9、10、13……非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35。

查找过程：例如搜索28数据项，首先加载磁盘块1到内存中，发生一次I/O，用二分查找确定在P2指针。接着发现28在26和30之间，通过P2指针的地址加载磁盘块3到内存，发生第二次I/O。用同样的方式找到磁盘块8，发生第三次I/O。

真实的情况是，上面3层的B+Tree可以表示上百万的数据，上百万的数据只发生了**三次I/O**而不是上百万次I/O，时间提升是巨大的。



### 2. Explain

 ![img](img/180607170774892.png)

索引使用情况在possible_keys、key和key_len三列，接下来我们先从左到右依次讲解。

#### 1.id

```mysql
-- id相同,执行顺序由上而下（记录越少的在前面先执行，小表驱动大表）
explain select u.*,o.* from user_info u,order_info o where u.id=o.user_id;
```

 ![img](img/180607170774893.png) 

```mysql
-- id不同,值越大越先被执行
explain select * from  user_info  where id=(select user_id from order_info where  product_name ='p8');
```

  ![img](img/180607170774894.png) 

#### 2.select_type

可以看id的执行实例，总共有以下几种类型：

- SIMPLE： 表示此查询不包含 UNION 查询或子查询
- PRIMARY： 表示此查询是最外层的查询
- SUBQUERY： 子查询中的第一个 SELECT
- UNION： 表示此查询是 UNION 的第二或随后的查询
- DEPENDENT UNION： UNION 中的第二个或后面的查询语句, 取决于外面的查询。 Mysql 先执行外查询，内查询根据这个查询结果(如执行计划里所述，38196 rows)的每一条记录组成新的查询语句后执行。 非常慢
- UNION RESULT, UNION 的结果
- DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果.
- DERIVED：衍生，表示导出表的SELECT（FROM子句的子查询）

#### 3.table

```mysql
-- table表示查询涉及的表或衍生的表：
explain select tt.* from (select u.* from user_info u,order_info o where u.id=o.user_id and u.id=1) tt
-- id为1的<derived2>的表示id为2的u和o表衍生出来的。
```

  ![img](img/180607170774895.png) 



#### 4.type

> type 字段比较重要，它提供了判断查询是否高效的重要依据依据。 通过 type 字段，我们判断此次查询是 全表扫描 还是 索引扫描等。

 ![img](img/180607170774896.png) 
type 常用的取值有:

- null：不用访问表或者索引，直接就能得到结果。`select 1 from test`
- system: 表中只有一条数据， 这个类型是特殊的 const 类型。
- const: 针对**主键或唯一索引**的等值查询扫描，最多只返回一行数据，这个匹配行的其他列的值可以被优化器在当前查询中当作常量来处理。 const 查询速度非常快， 因为它仅仅读取一次即可。例如下面的这个查询，它使用了主键索引，因此 type 就是 const 类型的：`explain select * from user_info where id = 2`；
- eq_ref: 此类型通常出现在多表的 join 查询，与ref的区别在于使用唯一索引，表示对于前表的每一个结果，都只能匹配到后表的一行结果。并且查询的比较操作通常是 =，查询效率较高。例如：`explain select * from user_info, order_info where user_info.id = order_info.user_id`;
- ref: 单表使用非唯一索引或者唯一索引的前缀扫描，返回一行以上记录。此类型通常出现在多表的 join 查询，针对于非唯一或非主键索引，或者是使用了 最左前缀 规则索引的查询。例如下面这个例子中， 就使用到了 ref 类型的查询：`explain select * from user_info, order_info where user_info.id = order_info.user_id AND order_info.user_id = 5`
- range: 表示使用**索引范围查询**，通过索引字段范围获取表中部分数据记录。这个类型通常出现在 =, <>, >, >=, <, <=, <=>, BETWEEN, IN() 操作中。例如下面的例子就是一个范围查询：`explain select * from user_info  where id between 2 and 8`；
- index: 表示全索引扫描(full index scan)，和 ALL 类型类似，只不过 ALL 类型是全表扫描，而 index 类型则仅仅扫描所有的索引， 而不扫描数据。index 类型通常出现在：所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据。当是这种情况时，Extra 字段 会显示 Using index。
- ALL: 表示全表扫描，这个类型的查询是性能最差的查询之一。通常来说， 我们的查询不应该出现 ALL 类型的查询，因为这样的查询在数据量大的情况下，对数据库的性能是巨大的灾难。 如一个查询是 ALL 类型查询， 那么一般来说可以对相应的字段添加索引来避免。

通常来说, 不同的 type 类型的性能关系如下:

> ALL < index < range ~ index_merge < ref < eq_ref < const < system
>
> ALL 类型因为是全表扫描， 因此在相同的查询条件下，它是速度最慢的。而 index 类型的查询虽然不是全表扫描，但是它扫描了所有的索引，因此比 ALL 类型的稍快.后面的几种类型都是利用了索引来查询数据，因此可以过滤部分或大部分数据，因此查询效率就比较高了。
>
> ![image-20201216165616977](img/image-20201216165616977.png)

##### 1.ref

> 使用普通索引

```mysql
select * from user_info where age =20 ;
explain select * from user_info  where age =20 ;
ALTER TABLE `user_info` ADD INDEX (`age`) ;-- 使用索引后结果数据量和查询的行数是一样的
```

​	![1574599794015](img/1574599794015.png)

​	![1574599676414](img/1574599676414.png)

​	![](img/1574599871331.png)

#### 5.possible_keys

它表示 mysql 在查询时，可能使用到的索引。 注意，即使有些索引在 possible_keys 中出现，但是并不表示此索引会真正地被 mysql 使用到。 mysql 在查询时具体使用了哪些索引，由 key 字段决定。

#### 6.key

此字段是 mysql 在当前查询时所真正使用到的索引。比如请客吃饭,possible_keys是应到多少人，key是实到多少人。当我们没有建立索引时：

> explain select o.* from order_info o where o.product_name= 'p1' and o.productor='whh';
>
> ​	drop index idx_name_productor on order_info;

  ![1574587016482](img/1574587016482.png) 

建立复合索引后再查询：

 ![1574587095151](img/1574587095151.png)

#### 7.key_len

表示查询优化器使用了索引的字数，这个字段可以评估组合索引是否完全被使用。

#### 8.ref

这个表示显示索引的哪一列被使用了，如果可能的话，是一个常量。前文的type属性里也有ref，注意区别。

 ![img](img/180607170774899.png) 

#### 9.rows

rows 也是一个重要的字段，mysql 查询优化器根据统计信息，估算 sql 要查找到结果集需要扫描读取的数据行数，这个值非常直观的显示 sql 效率好坏， 原则上 rows 越少越好。可以对比key中的例子，一个没建立索引钱，rows是9，建立索引后，rows是4。

#### 10.extra

 ![img](img/1806071707748910.png) 

explain 中的很多额外的信息会在 extra 字段显示, 常见的有以下几种内容:

- using filesort ：表示 mysql 需额外的排序操作，不能通过索引顺序达到排序效果。一般有 using filesort都建议优化去掉，因为这样的查询 cpu 资源消耗大。
- using index：覆盖索引扫描，表示查询在索引树中就可查找所需数据，不用扫描表数据文件，往往说明性能不错。
- using temporary：查询有使用临时表, 一般出现于排序， 分组和多表 join 的情况， 查询效率不高，建议优化。
- using where ：表名使用了where过滤。
- Using join buffer (Block Nested Loop) :  嵌套循环 

### 3. 优化案例

```mysql
explain select u.*,o.* from user_info u LEFT JOIN order_info o on u.id = o.user_id;
-- left join，一定是先循环左表，无论大小，
```

```mysql
-- 执行结果，type有ALL，并且没有使用索引，扫描了9行数据，Extra使用的是嵌套循环：Using join buffer (Block Nested Loop)
```

 ![img](img/1806071707748911.png) 

```mysql
-- 开始优化，在关联列user_id上创建索引，明显看到type列的ALL变成ref，并且用到了索引，rows也从扫描9行变成了1行(只是扫描索引的表，具体数据的表只是扫描了一行)
```

<img src="img/1574599128176.png" alt="1574599128176" style="zoom:80%;" /> 

```mysql
-- 这里面一般有个规律是：左链接索引加在右表上面，右链接索引加在左表上面。
```



### 4. 是否需要创建索引

索引虽然能非常高效的提高查询速度，同时却会降低更新表的速度。实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引列也是要占用空间的。

**原则**：查询索引扫描行数最少。

 ![img](img/1806071707748913.jpg) 





## 数据库设计

1. 选择合适的数据库

   es，mongodb，mysql，oracle，sql server

2. 合适的存储引擎

   ```
   Mysql 中有两个引擎 MyISAM 和 InnoDB，每个引擎有利有弊。
   MyISAM 适用于一些大量查询的应用，但对于有大量写功能的应用不是很好。甚至你只需要update 一个字段整个表都会被锁起来。而别的进程就算是读操作也不行要等到当前 update 操作完成之后才能继续进行。另外， MyISAM 对于 select count(*)这类操作是超级快的。 
   InnoDB 的趋势会是一个非常复杂的存储引擎，对于一些小的应用会比 MyISAM 还慢，但是支持“行锁”，所以在写操作比较多的时候会比较优秀。并且，它支持很多的高级应用，例如：事务。
   ```

a. 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。

b. 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num is null 可以在 num 上设置默认值 0，确保表中 num 列没有 null 值，然后这样查询： select id from t where num=0  

c. 并不是所有索引对查询都有效， SQL 是根据表中数据来进行查询优化的，当索引列有大量数据重复时,查询可能不会去利用索引，如一表中有字段 sex， male、 female 几乎各一半，那么即使在 sex 上建了索引也对查询效率起不了作用。

d. 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过 6 个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。   如果你有一些表，它们收集数据且不经常被搜索，则在有必要之前不要索引它们。（索引可根据需要添加和删除。）  

e. 应尽可能的避免更新索引数据列，因为索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新索引数据列，那么需要考虑是否应将该索引建为索引。   

f. 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。  

g. 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。

h. 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。

i. 避免频繁创建和删除临时表，以减少系统表资源的消耗。

j. 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。

k. 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先 create table，然后 insert  .

l. 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 droptable ，这样可以避免系统表的较长时间锁定  

## 高效的sql

```mysql
-- 当只要一行数据时使用limit1	
	查询时如果已知会得到一条数据，这种情况下加上limit1会增加性能。因为mysql数据库引擎会在找到一条结果停止搜索，而不是继续查询下一条是否符合标准直到所有记录查询完毕。

-- 用 not exists 代替 not in
   Not exists 用到了连接能够发挥已经建立好的索引的作用， not in 不能使用索引。 Not in 是最慢的方式要同每条记录比较，在数据量比较大的操作红不建议使用这种方式。

-- 对操作符的优化，尽量不采用不走索引的操作符如：or ，is null ，is not null ，<>,!= 等
-- 通过使用多条SELECT语句和连接它们的UNION语句，你能看到极大的性能改进。
	实测 `where age in(15,20)` 和 `where age =20 or age =15` 不使用索引，使用union代替。
    `where age in(15)` 经过索引

-- in ，not in，也要慎用，否则会导致全表扫描，如： select id from t where num in(1,2,3)
-- 对于连续的数值，能用 between 就不要用 in 了： select id from t where num between 1 and 3

-- 某个字段总要拿来搜索，为其建立索引

-- 最好不要给数据库留null

-- join 的时候 尽量把牵涉到多表联合的查询拆分多个 query（多个连表查询效率低，容易到之后锁表（锁几个表）和阻塞）。  
	select * from admin left join log on admin.admin_id = log.admin_id where log.admin_id>10 如何优化?
	优化为： select * from (select * from admin where admin_id>10) T1 lef join log on T1.admin_id =log.admin_id。
	
-- limit 的基数比较大时使用 between 要求索引必须是连续的，不然不能用

-- 尽量避免在列上做运算、函数，这样导致索引失效	
	例如： select * from admin where year(admin_time)>2014
	优化为： select * from admin where admin_time > '2014-01-01';
	
-- 自连接使用子表连接父表，例如父类别和子类别，直接回表，不用走索引查询，因为子类已经知道父类的位置，父类不知道子类在哪里

-- 一般来说，存储过程执行得比一条一条地执行其中的各条MySQL语句快。

e. 如果在 where 子句中使用参数，也会导致全表扫描。因为 SQL 只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： select id from t where num=@num 可以改为强制查询使用索引： select id from t with(index(索引名)) where num=@num

i. 不要写一些没有意义的查询，如需要生成一个空表结构： select col1,col2 into #t from t where 1=0 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(…)

j. 很多时候用 exists 代替 in 是一个好的选择： select num from a where num in(select num from b)用下面的语句替换： select num from a where exists(select 1 from b where num=a.num)

k. 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。

l. 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过 1 万行，那么就应该考虑改写。

m. 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。

n. 尽量避免大事务操作，提高系统并发能力。  

--  有的操作（包括INSERT）支持一个可选的DELAYED关键字，如果使用它，将把控制立即返回给调用程序，并且一旦有可能就实际执行该操作。

-- LIKE很慢。一般来说，最好是使用FULLTEXT而不是LIKE。
```

## 其他

```mysql
 -- 在导入数据时，应该关闭自动提交。你可能还想删除索引（包括FULLTEXT索引），然后在导入完成后再重建它们。
```

## java方面

1. 尽可能的少造对象。
2. 合理摆正系统设计的位置。大量数据操作，和少量数据操作一定是分开的。大量的数据操作，肯定不是ORM框架搞定的。，
3. 使用 jDBC 链接数据库操作数据
4. 控制好内存，让数据流起来，而不是全部读到内存再处理，而是边读取边处理；
5. 合理利用内存，有的数据要缓存  



# 安全问题

### sql 注入

#### 问题

1. 普通sql注入

   ```
   当执行的 sql 为 select * from user where username = “admin” or “a” =“a” 时， sql 语句恒成立，参数 admin 毫无意义。
   ```

2. 二次注入

   一般表拆分，如果一个table转义，相关的另一个table不转义，那么就会对另一个table造成攻击。

   **为了预防SQL注入攻击，程序将用户输入进行了转义，但是这些数据却又在“未被转义”的查询窗体中重复使用。**

   以PHP为例，当开启了magic_quotes_gpc之后，将会对特殊字符转义，

   ```mysql
   -- 将 ' 转义为 \' SQL语句
   insert into userinfo(id,username,password) values (1,'$username','$password')
   
   -- 通过网站插入数据：id为1、username 为 admin' -- 、password为123456，那么SQL语句如下：
   insert into userinfo(id,username,password) values (1,'admin\' -- ','123456')
   
   -- 但是在插入数据库后却没有“\”
   +----+------------+-----------+
   | id |  username  |  password |
   +----+------------+-----------+
   |  1 | admin' --  |   123456  |     '
   +----+------------+-----------+  
   
   -- 假设程序允许用户更改密码，用户名为admin' -- ,上面的查询就变成了这样：
   update users set password = '[new_password]' where username = 'admin' -- '
   因此攻击者通过注册一个admin' --用户修改了admin的密码
   ```




#### 防御

1. **PreparedStatement（简单又有效的方法）**：如， `select * from user where username = ？`

   原理：

   - sql注入只对sql语句的准备(编译)过程有破坏作用， 而PreparedStatement已经准备好了，是SQL引擎会预先进行语法分析，产生语法树，生成执行计划。执行阶段只是把输入串作为数据处理, 而不再对sql语句进行解析,准备,因此也就避免了sql注入问题。

2. Mybatis 框架中的 mapper 方式中的 `#{name}`也能很大程度的防止 sql 注入。（`${name}`无法防止 sql 注入）。 

   > 前者底层也是使用PreparedStatement，后者拼接sql

3. 存储过程、函数

4. **拼接sql语句时特别注意**：

   - 检查参数字符串的数据类型，字符长度

     比如 id 只能是 int型，复杂情况可以使用正则表达式来判断。

   - 安全函数，排除字符串、特殊字符

   - ESAPI.md

     ```java
     MySQLCodec codec = new MySQLCodec(Mode.STANDARD);
     name = ESAPI.encoder().encodeForSQL(codec, name);//该函数会将 name 中包含的一些特殊字符进行编码，这样 sql 引擎就不会将name中的字符串当成sql命令来进行语法分析了。
     String sql = "select id,no from user where name=" + name;
     ```

5. 通过对数据库强制执行最小权限原则，来减缓SQL注入漏洞的影响。籍此，应用程序的每一个软件组件都只能访问、并仅影响它所需要的资源。

6. 对访问数据库的Web应用程序采用Web应用防火墙(Web Application Firewall，WAF)。这有助于识别出针对SQL注入的各种尝试，进而防止此类尝试作用到应用程序上。

7. 避免在生产环境中，直接输出错误信息，因为这些错误信息有可能被攻击者利用。

8. 对用户敏感信息特别是密码做严格加密处理。



# 系统设置

### 配置

https://blog.csdn.net/itmr_liu/article/details/80851266
**my.ini文件**
在C:\ProgramData\MySQL\MySQL Server 8.0\目录下
**Path环境变量**

**启动关闭MySQL**

	1. net stop mysql
	net start mysql
	所有Windows服务都可以通过这两个命令实现
 	2. 计算机服务

**cmd中操作**

![计算机生成了可选文字: ·mysq|部分（md执行参数： -u代表雄户名 -p代密码 一P代表端口号 一h代表主机名 -V输出当前版丕号 --prompt为修改mysq示符命令 mysqliE出：exit或quit或\p D完整的日 ·\d当前数据库 ·\h服务器名称 ·\u当前户 ·USE+xxx打开x××名称的数据库 cls清屏 mysql>selectversion(img/clip_image001-1580397849825.png);显刁孓当前MYsq《版丕 mysql>selectnow()；显示圭前时间 mysql>selectuser()显示圭前雄F名 mysql>selectdatabase()显示圭前雄F打开的数据库](file:///C:/Users/TJR_S/AppData/Local/Temp/msohtmlclip1/01/clip_image001.png)

### sql-mode

```mysql
select @@global.sql_mode\G
-- global.sql_mode : NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION
```

最后得出结论

1. 如果sql_mode 没有设置STRICI_TRANS_TABLES，则在插入记录时，如果有非空字段没有值 而且没有设置默认值，则引擎会自动填充（int类型 填充0 string类型 填充 '' timestamp 类型填充 当前时间戳（2018-06-22 19:54:52）

2. 标准推荐设置 global.sql_mode : STRICI_TRANS_TABLES,NO_ENGINE_SUBSTITUTION

   在mysql配置文件my.cnf 或my.ini 中添加 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES

   

资料连接： https://www.cnblogs.com/zengkefu/p/5636614.html  

###   status和variables

 ![1574487519959](img/1574487519959.png)

 https://blog.csdn.net/andyzhaojianhui/article/details/50052117 

### 编码

>   统一编码 ，  建数据库和建表时应尽量使用统一的编码，强烈推荐的是 utf8 编码  。  在安装时就一定要设置为 utf8 编码  

```mysql
-- show编码
show variables like “%colla%”;
show variables like “%char%”
-- 其中 collation，代表了字符串排序（比较）的规则，如果值是 utf8_general_ci,代表使用 utf8 字符集大小写不敏感的自然方式比较。

-- 修改数据库默认编码为 utf8
ALTER DATABASE imooc DEFAULT CHARACTER SET 'utf8';
SET character_set_client='utf8';
SET character_set_connection='utf8';
SET character_set_results='utf8';
```

 <img src="img/1574855910578.png" alt="1574855910578"  />

![](img/clip_image001-1580397781489.png)

# 架构

 ![1574685946512](img/1574685946512.png)

### 各模块

1）、连接管理与安全验证是什么？

每个客户端都会建立一个与服务器连接的线程，服务器会有一个线程池来管理这些 连接；如果客户端需要连
接到 MYSQL 数据库还需要进行验证，包括用户名、密码、 主机信息等。
（2）、解析器是什么？
解析器的作用主要是分析查询语句，最终生成解析树；首先解析器会对查询语句的语法进行分析，分析语法是否
有问题。还有解析器会查询缓存，如果在缓存中有对应的语句，就返回查询结果不进行接下来的优化执行操作。前提是
缓存中的数据没有被修改，当然如果被修改了也会被清出缓存。
（3）、优化器怎么用？
优化器的作用主要是对查询语句进行优化操作，包括选择合适的索引，数据的读取方式，包括获取查询的开销信
息，统计信息等，这也是为什么图中会有优化器指向存储引擎的箭头。之前在别的文章没有看到优化器跟存储引擎之间的关系，在这里我个人的理解是因为优化器需要通过存储引擎获取查询的大致数据和统计信息。
（4）、执行器是什么？
执行器包括执行查询语句，返回查询结果，生成执行计划包括与存储引擎的一些处理操作。

### MyISAM 存储引擎

MyISAM 是 MySQL 官方提供默认的存储引擎，其特点是不支持事务、表锁和全文索引，对于一些 OLAP（联机分析处理）系统，操作速度快。每个 MyISAM 在磁盘上存储成三个文件。文件名都和表名相同，扩展名分别是.frm（存储表定义）、 .MYD (MYData，存储数据)、 .MYI (MYIndex，存储索引)。这里特别要注意的是 MyISAM 不缓存数据文件，只缓存索引文件。

### InnoDB 存储引擎

InnoDB 存储引擎支持事务，主要面向 OLTP（联机事务处理过程）方面的应用，其特点是行锁设置、支持外键，并支持类似于 Oracle 的非锁定读，即默认情况下读不产生锁。 InnoDB 将数据放在一个逻辑表空间中（类似 Oracle）。

InnoDB 通过多版本并发控制来获得高并发性，实现了 ANSI 标准的 4 种隔离级别，默认为 Repeatable，使用一种被称为 next-key locking 的策略避免幻读。

对于表中数据的存储， InnoDB 采用类似 Oracle 索引组织表 Clustered 的方式进行存储。

InnoDB 存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比 Myisam 的存储引擎， InnoDB 写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。  

# 其他命令

https://blog.csdn.net/starnight_cbj/article/details/4492555

**查看连接数，状态**

```mysql

-- 如果是root帐号，你能看到所有用户的当前连接。如果是其它普通帐号，只能看到自己占用的连接。
show processlist; -- 只列出前100条
show full processlist; -- 全列

-- 将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中；
set long_query_time=0;
```

索引

```mysql
-- 强制使用索引a
select * from t force index(a) where a between 10000 and 20000; 

-- 重新统计索引信息，如果你发现explain的结果预估的rows值跟实际情况差距比较大，可以采用这个方法来处理。
analyze table t ;

-- 存储索引统计
-- 设置为on的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。
-- 设置为off的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。
-- 由于是采样统计，所以不管N是20还是8，这个基数都是很容易不准的。
设置参数innodb_stats_persistent
```



# 经验

## 金额(金钱)相关的数据存储类型

#### int

对于游戏币等代币，一般存储为int类型是可行的。

问题在于越界，int类型长度为32位。

在存储人民币相关的金额的时候，最大只能存储2^32，大约42亿的数值。

#### Decimal

Decimal为专门为财务相关问题设计的数据类型。

> DECIMAL从MySQL 5.1引入，列的声明语法是DECIMAL(M,D)。在MySQL 5.1中，参量的取值范围如下：
>
> ·M是数字的最大数（精度）。其范围为1～65（在较旧的MySQL版本中，允许的范围是1～254），M 的默认 值是10。
>
> ·D是小数点右侧数字的数目（标度）。其范围是0～30，但不得超过M。
>
> 说明：float占4个字节，double占8个字节，decimail(M,D)占M+2个字节。
>
> 如DECIMAL(5,2) 的最大值为 9 9 9 . 9 9，因为有7 个字节可用。

能够解决数据的范围和精度的问题。


#### float

注意mysql 中一定要用decimal标识货币的值！不要用float了，举例说明：

```mysql
CREATE TABLE LedgerEntries (
	LedgerEntryID INT PRIMARY KEY Auto_Increment NOT NULL,
	CustomerID INT NOT NULL,
	Amount FLOAT NOT NULL
);

-- 然后插入一些数据；
INSERT INTO LedgerEntries (CustomerID, Amount)
VALUES
	(1, 3.14);

INSERT INTO LedgerEntries (CustomerID, Amount)
VALUES
	(1, 30000.14);

Insert Into LedgerEntries (CustomerID, Amount)
Values (1, 30000.14);

-- 最后查询下
Select * From LedgerEntries;

-- 看到了么？没了最后的一位！，因此，赶紧用decimal吧
+---------------+------------+---------+
| LedgerEntryID | CustomerID | Amount |
+---------------+------------+---------+
| 1 | 1 | 3.14 |
| 2 | 1 | 30000.1 |
+---------------+------------+---------+
```

## 在数据库上实现每3秒最多只插入一条记录

https://www.jianshu.com/p/3695f2be9651

# **M**ySQL 8.0

**修改密码**
**MySQL下使用语句**
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '你的密码';  

**MySQL8.0.11的配置文件**
my.ini文件在C:\ProgramData\MySQL\MySQL Server 8.0\目录下，这个目录是一个隐藏目录。
改变端口

![client 和 mysql  的 端 口 改 成 你 要 改 的 端 口 ](img/clip_image001-1580398188373.png)

改变编码
MySQL最好使用UTF8MB4，而不要使用UTF8

![[client]  default-cha racter-set=utf8mb4  [mysql]  default-character-set=utf8mb4  [mysqld]  character-set-client-handshake=FALSE  character-set-server=utf8mb4  collation-server=utf8mb4 unicode ci  init connect='SET NAMES utf8mb4' ](img/clip_image001-1580398194318.png)